import streamlit as st
from ollama import chat, generate



# rÃ©glages page devoirs #

st.set_page_config(
    page_title="Assistant",
    page_icon="ðŸ‘·",
    layout="wide"
)


st.markdown("""
    <style>
        div.stMarkdown h1 {
            margin-bottom: -2vhvh; 
        }
        
        div.stMarkdown h6 {
            margin-bottom: -10vh; 
        }
    </style>
""", unsafe_allow_html=True)



# titre sous titre #

st.markdown("<h1>Communiquer facilement avec votre assistant IA personel ðŸ‘·</h1>", unsafe_allow_html=True)
st.markdown("<h6>ici vous pouvez communiquer avec votre chatbot ia.</h6>", unsafe_allow_html=True)
st.markdown("---")


# Initialiser la mÃ©moire du chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Afficher lâ€™historique
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# saisie msg #

prompt = st.chat_input(
    "Ã©crivez quelque chose...",
    accept_file=False,
)



if prompt:
    user_text = prompt

    # Ajouter le message utilisateur
    st.session_state.messages.append({"role": "user", "content": user_text})
    with st.chat_message("user"):
        st.markdown(user_text)

    # Envoyer tout lâ€™historique Ã  Ollama
    response = chat(model="mistral", messages=st.session_state.messages)

    # RÃ©cupÃ©rer la rÃ©ponse
    ai_msg = response["message"]["content"]

    # Ajouter la rÃ©ponse dans lâ€™historique
    st.session_state.messages.append({"role": "assistant", "content": ai_msg})

    # Afficher la rÃ©ponse
    with st.chat_message("assistant"):
        st.markdown(ai_msg)


